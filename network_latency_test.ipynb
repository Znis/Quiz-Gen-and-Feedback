{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T14:38:20.359942Z","iopub.status.busy":"2024-10-02T14:38:20.359479Z","iopub.status.idle":"2024-10-02T14:38:36.148565Z","shell.execute_reply":"2024-10-02T14:38:36.147237Z","shell.execute_reply.started":"2024-10-02T14:38:20.359901Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting groq\n","  Downloading groq-0.11.0-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.10/site-packages (from groq) (4.4.0)\n","Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from groq) (1.9.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from groq) (0.27.0)\n","Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from groq) (2.9.2)\n","Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from groq) (1.3.1)\n","Requirement already satisfied: typing-extensions<5,>=4.7 in /opt/conda/lib/python3.10/site-packages (from groq) (4.12.2)\n","Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->groq) (3.7)\n","Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->groq) (1.2.0)\n","Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->groq) (2024.8.30)\n","Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->groq) (1.0.5)\n","Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->groq) (2.23.4)\n","Downloading groq-0.11.0-py3-none-any.whl (106 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.5/106.5 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hInstalling collected packages: groq\n","Successfully installed groq-0.11.0\n"]}],"source":["!pip install groq"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T14:44:34.133234Z","iopub.status.busy":"2024-10-02T14:44:34.132714Z","iopub.status.idle":"2024-10-02T14:44:34.139932Z","shell.execute_reply":"2024-10-02T14:44:34.138223Z","shell.execute_reply.started":"2024-10-02T14:44:34.133186Z"},"trusted":true},"outputs":[],"source":["import os\n","import time\n","from datetime import datetime\n","from groq import Groq\n","import math"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T14:42:05.004987Z","iopub.status.busy":"2024-10-02T14:42:05.004372Z","iopub.status.idle":"2024-10-02T14:42:05.01208Z","shell.execute_reply":"2024-10-02T14:42:05.010446Z","shell.execute_reply.started":"2024-10-02T14:42:05.004933Z"},"trusted":true},"outputs":[],"source":["os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T14:45:02.965447Z","iopub.status.busy":"2024-10-02T14:45:02.964983Z","iopub.status.idle":"2024-10-02T14:45:02.97836Z","shell.execute_reply":"2024-10-02T14:45:02.976583Z","shell.execute_reply.started":"2024-10-02T14:45:02.965404Z"},"trusted":true},"outputs":[],"source":["def measure_feedback_latency(questions, score, time_elapsed):\n","    try:\n","        # Start timing\n","        start_time = time.time()\n","        \n","        # Round up the time elapsed\n","        rounded_time = math.ceil(time_elapsed)\n","        from groq import Groq\n","        # Generate the feedback\n","        client = Groq(api_key=\"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\")\n","        completion = client.chat.completions.create(\n","            model=\"llama3-8b-8192\",\n","            messages=[\n","                {\n","                    \"role\": \"system\", \n","                    \"content\":f\"\"\"\n","                         A user has completed a quiz with the following statistics:\n","        \n","                        - Total Questions: {questions}\n","                        - Correct Answers: {score}\n","                        - Time Taken: {rounded_time} seconds\n","        \n","                        Based on the user's performance, provide constructive feedback on their quiz attempt. \n","                        Consider the user's score and the time taken. Offer encouragement and suggest areas for improvement.\n","                        Please keep feedback short and sweet.\n","                        \"\"\"\n","                },\n","                {\"role\": \"user\", \"content\": f\"#Questions:{questions},#Score:{score},#time taken:{rounded_time},\"},\n","            ],\n","            max_tokens=150,\n","            temperature=0.5,\n","            top_p=0.9\n","        )\n","        \n","        # Calculate latency\n","        end_time = time.time()\n","        latency = (end_time - start_time) * 1000  # Convert to milliseconds\n","        \n","        # Get the feedback content\n","        feedback = completion.choices[0].message.content\n","        \n","        return {\n","            'feedback': feedback,\n","            'latency': latency,\n","            'timestamp': datetime.now(),\n","            'success': True\n","        }\n","        \n","    except Exception as e:\n","        return {\n","            'feedback': None,\n","            'latency': None,\n","            'timestamp': datetime.now(),\n","            'success': False,\n","            'error': str(e)\n","        }\n"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T14:45:05.366958Z","iopub.status.busy":"2024-10-02T14:45:05.365929Z","iopub.status.idle":"2024-10-02T14:45:05.748825Z","shell.execute_reply":"2024-10-02T14:45:05.747544Z","shell.execute_reply.started":"2024-10-02T14:45:05.366908Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Feedback Generated Successfully:\n","Latency: 374.24 ms\n","Timestamp: 2024-10-02 14:45:05.744795\n","\n","Feedback:\n","Great effort on your quiz attempt! You scored 8 out of 10, which is an impressive 80%! You've demonstrated a strong understanding of the material and should be proud of your achievement.\n","\n","However, there's always room for improvement. Take a closer look at the two questions you got wrong and see if you can identify any common mistakes or areas where you can brush up.\n","\n","Additionally, consider how you can manage your time more effectively. You took 301 seconds to complete the quiz, which is a bit longer than ideal. Practice pacing yourself and making the most of your time to achieve an even higher score next time.\n","\n","Keep up the good work and keep pushing yourself to improve!\n"]}],"source":["def main():\n","    # Example values\n","    questions = 10\n","    score = 8\n","    time_elapsed = 300.75  # example time in seconds\n","    \n","    result = measure_feedback_latency(questions, score, time_elapsed)\n","    \n","    if result['success']:\n","        print(f\"\\nFeedback Generated Successfully:\")\n","        print(f\"Latency: {result['latency']:.2f} ms\")\n","        print(f\"Timestamp: {result['timestamp']}\")\n","        print(f\"\\nFeedback:\\n{result['feedback']}\")\n","    else:\n","        print(f\"Error generating feedback: {result['error']}\")\n","\n","if __name__ == \"__main__\":\n","    main()"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T14:50:20.683693Z","iopub.status.busy":"2024-10-02T14:50:20.68315Z","iopub.status.idle":"2024-10-02T14:50:20.694366Z","shell.execute_reply":"2024-10-02T14:50:20.692924Z","shell.execute_reply.started":"2024-10-02T14:50:20.683647Z"},"trusted":true},"outputs":[],"source":["import statistics"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T14:50:20.847627Z","iopub.status.busy":"2024-10-02T14:50:20.847111Z","iopub.status.idle":"2024-10-02T14:50:20.863759Z","shell.execute_reply":"2024-10-02T14:50:20.862559Z","shell.execute_reply.started":"2024-10-02T14:50:20.847582Z"},"trusted":true},"outputs":[],"source":["def measure_feedback_latency(questions, score, time_elapsed, num_samples=5):\n","    latencies = []\n","    feedbacks = []\n","    \n","    print(f\"Making {num_samples} API calls to calculate average latency...\")\n","    \n","    for i in range(num_samples):\n","        try:\n","            # Start timing\n","            start_time = time.time()\n","            \n","            # Round up the time elapsed\n","            rounded_time = math.ceil(time_elapsed)\n","            \n","            from groq import Groq\n","        # Generate the feedback\n","            client = Groq(api_key=os.getenv(\"GROQ_API_KEY\"))\n","            \n","            # Generate the feedback\n","            completion = client.chat.completions.create(\n","                model=\"llama3-8b-8192\",\n","                messages=[\n","                    {\n","                        \"role\": \"system\", \n","                        \"content\": f\"\"\"\n","                            A user has completed a quiz with the following statistics:\n","                            - Total Questions: {questions}\n","                            - Correct Answers: {score}\n","                            - Time Taken: {rounded_time} seconds\n","                            Based on the user's performance, provide constructive feedback on their quiz attempt. \n","                            Consider the user's score and the time taken. Offer encouragement and suggest areas for improvement.\n","                            Please keep feedback short and sweet.\n","                        \"\"\"\n","                    },\n","                    {\"role\": \"user\", \"content\": f\"#Questions:{questions},#Score:{score},#time taken:{rounded_time},\"},\n","                ],\n","                max_tokens=150,\n","                temperature=0.5,\n","                top_p=0.9\n","            )\n","            \n","            # Calculate latency\n","            end_time = time.time()\n","            latency = (end_time - start_time) * 1000  # Convert to milliseconds\n","            \n","            latencies.append(latency)\n","            feedbacks.append(completion.choices[0].message.content)\n","            \n","            print(f\"Sample {i+1}: {latency:.2f} ms\")\n","            \n","            # Add a small delay between requests to avoid rate limiting\n","            time.sleep(1)\n","            \n","        except Exception as e:\n","            print(f\"Error in sample {i+1}: {str(e)}\")\n","            continue\n","    \n","    if latencies:\n","        stats = {\n","            'average_latency': statistics.mean(latencies),\n","            'median_latency': statistics.median(latencies),\n","            'min_latency': min(latencies),\n","            'max_latency': max(latencies),\n","            'std_dev': statistics.stdev(latencies) if len(latencies) > 1 else 0,\n","            'samples_collected': len(latencies),\n","            'timestamp': datetime.now(),\n","            'feedback': feedbacks[-1]  # Return the last generated feedback\n","        }\n","        return stats\n","    else:\n","        return None"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T14:50:21.002679Z","iopub.status.busy":"2024-10-02T14:50:21.002211Z","iopub.status.idle":"2024-10-02T14:50:27.49157Z","shell.execute_reply":"2024-10-02T14:50:27.490241Z","shell.execute_reply.started":"2024-10-02T14:50:21.002636Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Making 5 API calls to calculate average latency...\n","Sample 1: 319.45 ms\n","Sample 2: 279.57 ms\n","Sample 3: 276.38 ms\n","Sample 4: 291.65 ms\n","Sample 5: 306.57 ms\n","\n","Latency Statistics:\n","Average Latency: 294.72 ms\n","Median Latency: 291.65 ms\n","Minimum Latency: 276.38 ms\n","Maximum Latency: 319.45 ms\n","Standard Deviation: 18.22 ms\n","Samples Collected: 5\n","Timestamp: 2024-10-02 14:50:27.487183\n","\n","Last Generated Feedback:\n","Congratulations on completing the quiz!\n","\n","You scored an impressive 8/10, which shows you have a strong understanding of the material. Your accuracy is commendable, and you should be proud of your efforts!\n","\n","However, you might want to focus on improving your time management skills. You took 301 seconds to complete the quiz, which is a bit longer than expected. Practice makes perfect, so try to allocate your time more efficiently to maximize your score.\n","\n","Keep up the good work, and don't be afraid to challenge yourself with more quizzes!\n"]}],"source":["def main():\n","    # Example values\n","    questions = 10\n","    score = 8\n","    time_elapsed = 300.75\n","    \n","    # Calculate average latency with multiple samples\n","    results = measure_feedback_latency(questions, score, time_elapsed, num_samples=5)\n","    \n","    if results:\n","        print(\"\\nLatency Statistics:\")\n","        print(f\"Average Latency: {results['average_latency']:.2f} ms\")\n","        print(f\"Median Latency: {results['median_latency']:.2f} ms\")\n","        print(f\"Minimum Latency: {results['min_latency']:.2f} ms\")\n","        print(f\"Maximum Latency: {results['max_latency']:.2f} ms\")\n","        print(f\"Standard Deviation: {results['std_dev']:.2f} ms\")\n","        print(f\"Samples Collected: {results['samples_collected']}\")\n","        print(f\"Timestamp: {results['timestamp']}\")\n","        print(f\"\\nLast Generated Feedback:\\n{results['feedback']}\")\n","\n","if __name__ == \"__main__\":\n","    main()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def generate_explanation(context ,quiz_data_with_selected_options):\n","    from groq import Groq\n","    client = Groq(api_key=os.getenv(\"GROQ_API_KEY\"))\n","    \n","    completion = client.chat.completions.create(\n","        model=\"llama3-8b-8192\",\n","        messages=[\n","            {\n","                \"role\": \"system\", \n","                \"content\": (\n","                    \"Please generate explanation why the selected option is wrong or right based on the question and right option for the given context.\\nThe explanation should include complete explanation and avoid cutoff mid-sentence.\\nPlease rewrite the following explanation to be clear, concise, and no more than 4-5 sentences.\\nUser will provide context, question and right option and selected option in the format as \\\"#context: particular context, #Question: particular question, #Right option: right option, #Selected option: selected option\\\". \\n\"\n","                )\n","            },\n","            {\"role\": \"user\", \"content\": f\"#Question: {quiz_data_with_selected_options['question']}, #Right option: {quiz_data_with_selected_options['correct_option']}, #Selected option: {quiz_data_with_selected_options['selected_option']}\"},\n","        ],\n","        max_tokens=150,  # Lowering the token limit to control length\n","        temperature=0.5,  # Lowering temperature for less randomness and more focus\n","        top_p=0.9  # Optional: slightly lower top_p for more coherent completions\n","    )\n","\n","    return completion.choices[0].message.content"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T15:23:17.098442Z","iopub.status.busy":"2024-10-02T15:23:17.098Z","iopub.status.idle":"2024-10-02T15:23:17.113289Z","shell.execute_reply":"2024-10-02T15:23:17.111693Z","shell.execute_reply.started":"2024-10-02T15:23:17.098403Z"},"trusted":true},"outputs":[],"source":["def measure_feedback_latency(quiz_data_with_selected_options, num_samples=5):\n","    latencies = []\n","    feedbacks = []\n","\n","    print(f\"Making {num_samples} API calls to calculate latency...\")\n","\n","    for i in range(num_samples):\n","        try:\n","            # Get the question data for the current sample\n","            question_data = quiz_data_with_selected_options[i % len(quiz_data_with_selected_options)]\n","            \n","            # Start timing\n","            start_time = time.time()\n","\n","            # Generate the feedback (assuming the API works with the given model)\n","            client = Groq(api_key=os.getenv(\"GROQ_API_KEY\"))\n","            completion = client.chat.completions.create(\n","                model=\"llama3-8b-8192\",\n","                messages=[\n","                    {\n","                        \"role\": \"system\",\n","                        \"content\": (\n","                            \"Please generate explanation why the selected option is wrong or right based on the question and right option for the given context.\\n\"\n","                            \"The explanation should include complete explanation and avoid cutoff mid-sentence.\\n\"\n","                            \"Please rewrite the following explanation to be clear, concise, and no more than 4-5 sentences.\\n\"\n","                            \"User will provide context, question and right option and selected option in the format as \"\n","                            \"\\\"#context: particular context, #Question: particular question, #Right option: right option, #Selected option: selected option\\\". \\n\"\n","                        )\n","                    },\n","                    {\n","                        \"role\": \"user\",\n","                        \"content\": f\"#Question: {question_data['question']}, #Right option: {question_data['correct_option']}, #Selected option: {question_data['selected_option']}\"\n","                    }\n","                ],\n","                max_tokens=150,\n","                temperature=0.5,\n","                top_p=0.9\n","            )\n","\n","            # Calculate latency\n","            end_time = time.time()\n","            latency = (end_time - start_time) * 1000  # Convert to milliseconds\n","            latencies.append(latency)\n","            feedbacks.append(completion.choices[0].message.content)\n","\n","            print(f\"Sample {i+1}: {latency:.2f} ms\")\n","\n","            # Add a small delay between requests to avoid rate limiting\n","            time.sleep(1)\n","\n","        except Exception as e:\n","            print(f\"Error in sample {i+1}: {str(e)}\")\n","            continue\n","\n","    if latencies:\n","        stats = {\n","            'average_latency': statistics.mean(latencies),\n","            'median_latency': statistics.median(latencies),\n","            'min_latency': min(latencies),\n","            'max_latency': max(latencies),\n","            'std_dev': statistics.stdev(latencies) if len(latencies) > 1 else 0,\n","            'samples_collected': len(latencies),\n","            'timestamp': datetime.now(),\n","            'feedback': feedbacks[-1]  # Return the last generated feedback\n","        }\n","        return stats\n","    else:\n","        return None\n"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T15:24:21.850161Z","iopub.status.busy":"2024-10-02T15:24:21.849629Z","iopub.status.idle":"2024-10-02T15:24:28.30433Z","shell.execute_reply":"2024-10-02T15:24:28.303028Z","shell.execute_reply.started":"2024-10-02T15:24:21.850114Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Making 5 API calls to calculate latency...\n","Sample 1: 327.43 ms\n","Sample 2: 272.90 ms\n","Sample 3: 249.91 ms\n","Sample 4: 300.36 ms\n","Sample 5: 282.32 ms\n","\n","Latency Statistics:\n","Average Latency: 286.58 ms\n","Median Latency: 282.32 ms\n","Minimum Latency: 249.91 ms\n","Maximum (Worst-case) Latency: 327.43 ms\n","Standard Deviation: 29.19 ms\n","Samples Collected: 5\n","Timestamp: 2024-10-02 15:24:28.299590\n","\n","Last Generated Feedback:\n","The selected option, \"Increasing the number of human-made structures\", is incorrect. The right option, \"Solving environmental issues and addressing climate change\", is correct because recent news has highlighted the importance of biology in addressing global environmental issues and climate change. Biology plays a crucial role in understanding the impact of human activities on the environment and developing sustainable solutions to mitigate climate change.\n"]}],"source":["def main():\n","    # Example quiz data\n","    quiz_data_with_selected_options = [\n","    {\n","        'question': 'What was the first form of life on Earth?',\n","        'correct_option': 'Microorganisms',\n","        'selected_option': 'Plants'\n","    },\n","    {\n","        'question': 'When did humans in their current appearance emerge on Earth?',\n","        'correct_option': '300,000 years ago',\n","        'selected_option': '2.5 million years ago'\n","    },\n","    {\n","        'question': 'What is a key aspect of the scientific method?',\n","        'correct_option': 'Making careful observations and testing hypotheses through experiments',\n","        'selected_option': 'Drawing conclusions without experimentation'\n","    },\n","    {\n","        'question': 'Which of the following is not considered a recent development in the biological timeline?',\n","        'correct_option': 'Microorganisms',\n","        'selected_option': 'Mammals'\n","    },\n","    {\n","        'question': 'What global effort is biology related to in recent news?',\n","        'correct_option': 'Solving environmental issues and addressing climate change',\n","        'selected_option': 'Increasing the number of human-made structures'\n","    },\n","    {\n","        'question': 'In which field is the scientific method harder to apply?',\n","        'correct_option': 'Archaeology and psychology',\n","        'selected_option': 'Physics and chemistry'\n","    },\n","    {\n","        'question': 'How long have mammals existed on Earth?',\n","        'correct_option': '130 to 250 million years',\n","        'selected_option': '300,000 years'\n","    },\n","    {\n","        'question': 'What is a global concern related to biology?',\n","        'correct_option': 'Outbreaks of Escherichia coli and Salmonella',\n","        'selected_option': 'Discovery of new chemical elements'\n","    },\n","    {\n","        'question': 'Which of the following diseases is biology actively researching for a cure?',\n","        'correct_option': 'AIDS, Alzheimer\\'s, and cancer',\n","        'selected_option': 'Common cold'\n","    },\n","    {\n","        'question': 'Why is the scientific method important in biology?',\n","        'correct_option': 'It helps scientists acquire knowledge through repeatable experiments.',\n","        'selected_option': 'It allows scientists to make assumptions without experiments.'\n","    }\n","]\n","\n","    \n","    # Calculate latency for feedback\n","    results = measure_feedback_latency(quiz_data_with_selected_options, num_samples=5)\n","    \n","    if results:\n","        print(\"\\nLatency Statistics:\")\n","        print(f\"Average Latency: {results['average_latency']:.2f} ms\")\n","        print(f\"Median Latency: {results['median_latency']:.2f} ms\")\n","        print(f\"Minimum Latency: {results['min_latency']:.2f} ms\")\n","        print(f\"Maximum (Worst-case) Latency: {results['max_latency']:.2f} ms\")\n","        print(f\"Standard Deviation: {results['std_dev']:.2f} ms\")\n","        print(f\"Samples Collected: {results['samples_collected']}\")\n","        print(f\"Timestamp: {results['timestamp']}\")\n","        print(f\"\\nLast Generated Feedback:\\n{results['feedback']}\")\n","        \n","if __name__ == \"__main__\":\n","    main()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30775,"isGpuEnabled":false,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
